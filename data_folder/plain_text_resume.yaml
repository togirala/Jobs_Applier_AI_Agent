personal_information:
  name: "Teja"
  surname: "Ogirala"
  # date_of_birth: "[Your Date of Birth]"
  country: "USA"
  city: "NY"
  address: "913A Prince St."
  zip_code: "10032"
  phone_prefix: "+1"
  phone: "8622273267"
  email: "teja.career@proton.me"
  github: "https://www.github.com/togirala"
  linkedin: "https://www.linkedin.com/in/togirala"

education_details:
  - education_level: "Master's Degree"
    institution: "Simon Fraser University"
    field_of_study: "Computer Science"
    # final_evaluation_grade: "[Your Final Evaluation Grade]"
    start_date: "2014"
    year_of_completion: "2017"
    # exam:
    #   exam_name_1: "[Grade]"
    #   exam_name_2: "[Grade]"
    #   exam_name_3: "[Grade]"
    #   exam_name_4: "[Grade]"
    #   exam_name_5: "[Grade]"
    #   exam_name_6: "[Grade]"

experience_details:
  - position: "Sr Data Engineer"
    company: "Epiq"
    employment_period: " 01/2023 - 08/2024"
    location: "Ottawa"
    industry: "Technology, Legal"
    key_responsibilities:
      - responsibility_1: "Led the design and implementation of a Microsoft Azure data lake and data processing pipeline using the Medallion model for an international law firm with 1,000+ lawyers across 10+ offices."
      - responsibility_2: "Managed data ingestion and optimized ETL processes using Parquet and Delta formats, streamlining data flow, reducing storage costs, and ensuring high-quality datasets, resulting in fewer data errors."
      - responsibility_3: "Built the first data platform implementation on Microsoft Fabric for any law firm in North America and collaborated closely with Microsoft on product optimization, resulting in improved performance and a 35% reduction in operational costs."
      - responsibility_4: "Implemented robust security measures and compliance protocols, delivering a scalable and secure data platform that supports advanced analytics and business intelligence initiatives, enabling faster and more informed decision-making."
    skills_acquired:
      - "Python"
      - "Azure"
      - "Synapse"
      - "Databricks"
      - "Spark"
      - "SQL"
      - "Microsoft Fabric"
      - "REST"
      - "API"
      - "DevOPS"
      - "Datalake"
      - "Power BI"
      - "ETL"

  - position: "Sr Data Engineer"
    company: "Morgan Stanley"
    employment_period: "11/2021 - 12/2022"
    location: "Montreal"
    industry: "Technology, Finance"
    key_responsibilities:
      - responsibility_1: "Implemented batch and streaming data pipelines to process large volumes of infrastructure data for 75,000 employees across 50 data centers, enhancing data handling efficiency."
      - responsibility_2: "Designed and developed internal process improvements, automating manual tasks and redesigning infrastructure for greater scalability, which reduced operational overhead."
      - responsibility_3: "Developed and integrated data egress APIs using OPENAPI Specification, creating API endpoints for various data providers, and dynamically managed Kafka topics to aggregate data into Snowflake."
    skills_acquired:
      - "Python"
      - "Java"
      - "Bash"
      - "Kafka"
      - "Snowflake"
      - "SQL"
      - "OPENAPI"
      - "ETL"

  - position: "Data Engineer"
    company: "Gazelle AI (acquired by Lightcast)"
    employment_period: "09/2019 - 10/2021"
    location: "Montreal"
    industry: "Technology, AI"
    key_responsibilities:
      - responsibility_1: "Engineered, deployed, and maintained data pipelines aggregating microservices data into a centralized data lake using AWS S3, AirFlow, and ElasticSearch, integrating data for approximately 12 million companies."
      - responsibility_2: "Built a high-throughput data platform capable of processing about 30 million rows concurrently, significantly enhancing data transformation efficiency."
      - responsibility_3: "Developed data tools for analytics and collaborated with stakeholders across all departments to resolve data-related technical issues and support their data infrastructure needs."
    skills_acquired:
      - "Python"
      - "AWS"
      - "Databricks"
      - "AirFlow"
      - "ElasticSearch"
      - "MongoDB"
      - "SQL"
      - "Postgres"

  - position: "Data Engineer"
    company: "BlackDuck Software (acquired by Synopsys)"
    employment_period: "03/2018 - 10/2018"
    location: "Burnaby"
    industry: "Technology, Compliance"
    key_responsibilities:
      - responsibility_1: "Architected data pipelines with custom ETL logic using Airflow and Azure Data Factory, building a knowledge base for 900k OSS products, and performed a data security audit on eight data sources to ensure best practices."
      - responsibility_2: "Implemented a recommendation system for OSS products, reducing security risks by 30% by identifying and avoiding vulnerabilities."
    skills_acquired:
      - "Python"
      - "AWS"
      - "Java"
      - "Scala"
      - "GCP"
      - "BigQuery"
      - "PostgreSQL"
      - "xgboost"
      - "sklearn"
      - "Docker"

  - position: "Research & Innovation Engineer"
    company: "SAP"
    employment_period: "05/2016 - 04/2017"
    location: "Vancouver"
    industry: "Technology, Saas, Compliance"
    key_responsibilities:
      - responsibility_1: "Independently implemented database architecture for an automated information monitoring system using Java and Scala on SAP Hana DB, tracking changes in approximately 1,300 web service agreements for risk management."
      - responsibility_2: "Additionally, developed a scoring system to evaluate Terms of Service for web services and APIs, providing the legal team with accurate assessments."
    skills_acquired:
      - "Python"
      - "SQL"
      - "Java"
      - "Scala"
      - "HANA"
      - "Akka"
      - "Docker"
      - "R"
      - "BI"

  - position: "Software Engineering Analyst"
    company: "Accenture"
    employment_period: "08/2012 - 08/2014"
    location: "Hyd"
    industry: "Technology"
    key_responsibilities:
      - responsibility_1: "Executed and administered data pipelines, generating OBIEE reports for daily transactions aggregating to $20 billion annually, and debugged 1,300 ETL mappings to meet SLAs for operations across the United States, Canada, and Central Europe."
    skills_acquired:
      - "ETL"
      - "Informatica"
      - "SQL"
      - "DAC"
      - "Oracle 11g"
      - "OBIEE"
      - "IBM DB2"


# projects:
#   - name: "[Project Name]"
#     description: "[Project Description]"
#     link: "[Project Link]"

#   - name: "[Project Name]"
#     description: "[Project Description]"
#     link: "[Project Link]"

achievements:
  - name: "ACE"
    description: "ACE - Accenture Celebrates Excellence Award"
  # - name: "[Achievement Name]"
  #   description: "[Achievement Description]"

certifications:
  - name: "Azure Data Engineer Associate"
    description: "InProgress"
  # - name: "[Certification Name]"
  #   description: "[Certification Description]"

languages:
  - language: "Engligh"
    proficiency: "Fluent"
  # - language: "[Language]"
  #   proficiency: "[Proficiency Level]"

# interests:
#   - "[Interest]"
#   - "[Interest]"
#   - "[Interest]"

availability:
  notice_period: "2 weeks"

salary_expectations:
  salary_range_usd: "150000 - 220000"

self_identification:
  gender: "Prefer not to say"
  pronouns: "Prefer not to say"
  veteran: "Prefer not to say"
  disability: "Prefer not to say"
  ethnicity: "Prefer not to say"


legal_authorization:
  eu_work_authorization: "No"
  us_work_authorization: "Yes"
  requires_us_visa: "Yes"
  requires_us_sponsorship: "No"
  # requires_eu_visa: "[Yes/No]"
  # legally_allowed_to_work_in_eu: "[Yes/No]"
  legally_allowed_to_work_in_us: "Yes"
  # requires_eu_sponsorship: "[Yes/No]"
  canada_work_authorization: "Yes"
  requires_canada_visa: "No"
  legally_allowed_to_work_in_canada: "Yes"
  requires_canada_sponsorship: "No"
  # uk_work_authorization: "[Yes/No]"
  # requires_uk_visa: "[Yes/No]"
  # legally_allowed_to_work_in_uk: "[Yes/No]"
  # requires_uk_sponsorship: "[Yes/No]"


work_preferences:
  remote_work: "Yes"
  in_person_work: "Yes"
  open_to_relocation: "Yes"
  willing_to_complete_assessments: "Yes"
  willing_to_undergo_drug_tests: "Yes"
  willing_to_undergo_background_checks: "Yes"
